"""FastMCP server for tracking agent-generated code."""

import os
import sys
import argparse
from mcp.server.fastmcp import FastMCP
import httpx
import uvicorn

# Initialize FastMCP server
mcp = FastMCP("AI Code Metrics Tracker")

# Get backend URL from environment or use default
BACKEND_URL = os.getenv("METRICS_BACKEND_URL", "http://localhost:8000")
http_client = httpx.AsyncClient(timeout=10.0)


@mcp.tool()
def track_agent_code(
    code: str,
    file_path: str,
    language: str = "unknown",
    code_type: str = "code",
    developer_id: str = "unknown",
) -> dict:
    """
    Track code generated by AI agent (MCP).

    Args:
        code: The code that was generated
        file_path: Path to the file where code was generated
        language: Programming language (python, javascript, etc.)
        code_type: Type of code - "code", "test", or "documentation"
        developer_id: Developer identifier

    Returns:
        Success response with lines tracked
    """
    # Count lines of code
    lines = len([line for line in code.split("\n") if line.strip()])

    if lines == 0:
        return {
            "success": False,
            "message": "No code to track (empty or whitespace only)",
        }

    # Determine event endpoint based on code_type
    endpoint_map = {
        "code": "/api/events/code",
        "test": "/api/events/test",
        "documentation": "/api/events/documentation",
    }

    endpoint = endpoint_map.get(code_type, "/api/events/code")

    # Prepare event payload
    event = {
        "source": "agent",
        "lines": lines,
        "file_path": file_path,
        "language": language,
        "developer_id": developer_id,
        "type": code_type,
    }

    # Add type-specific fields
    if code_type == "test":
        event["test_framework"] = "unknown"  # Can be enhanced
    elif code_type == "documentation":
        event["doc_type"] = "api-doc"  # Can be enhanced

    # Send to backend
    try:
        response = httpx.post(f"{BACKEND_URL}{endpoint}", json=event, timeout=5.0)
        response.raise_for_status()
        return {
            "success": True,
            "message": f"Agent code tracked: {lines} lines",
            "lines": lines,
            "code_type": code_type,
        }
    except httpx.RequestError as e:
        return {
            "success": False,
            "message": f"Failed to send event to backend: {str(e)}",
        }
    except httpx.HTTPStatusError as e:
        return {
            "success": False,
            "message": f"Backend error: {e.response.status_code}",
        }


@mcp.tool()
def track_agent_feature_completion(
    feature_description: str,
    files_modified: list[str],
    total_lines: int,
    developer_id: str = "unknown",
) -> dict:
    """
    Track when an AI agent completes a feature.

    Args:
        feature_description: Description of the completed feature
        files_modified: List of file paths that were modified
        total_lines: Total lines of code generated for this feature
        developer_id: Developer identifier

    Returns:
        Success response
    """
    # Send summary event to backend
    event = {
        "source": "agent",
        "lines": total_lines,
        "file_path": ", ".join(files_modified),
        "language": "mixed",
        "developer_id": developer_id,
        "type": "code",
        "metadata": {
            "feature_description": feature_description,
            "files_count": len(files_modified),
            "files": files_modified,
        },
    }

    try:
        response = httpx.post(f"{BACKEND_URL}/api/events/code", json=event, timeout=5.0)
        response.raise_for_status()
        return {
            "success": True,
            "message": f"Feature completion tracked: {total_lines} lines across {len(files_modified)} files",
            "total_lines": total_lines,
            "files_count": len(files_modified),
        }
    except httpx.RequestError as e:
        return {
            "success": False,
            "message": f"Failed to send event to backend: {str(e)}",
        }
    except httpx.HTTPStatusError as e:
        return {
            "success": False,
            "message": f"Backend error: {e.response.status_code}",
        }


@mcp.resource("metrics://developer/{developer_id}")
def get_developer_metrics(developer_id: str) -> str:
    """
    Get metrics for a specific developer.

    Args:
        developer_id: Developer identifier

    Returns:
        JSON string with developer metrics
    """
    try:
        response = httpx.get(
            f"{BACKEND_URL}/api/metrics/developer/{developer_id}",
            timeout=5.0,
        )
        response.raise_for_status()
        return response.text
    except httpx.RequestError as e:
        return f'{{"error": "Failed to get metrics: {str(e)}"}}'
    except httpx.HTTPStatusError as e:
        return f'{{"error": "Backend error: {e.response.status_code}"}}'


@mcp.resource("metrics://team")
def get_team_metrics() -> str:
    """
    Get team-wide metrics and leaderboard.

    Returns:
        JSON string with team metrics
    """
    try:
        response = httpx.get(f"{BACKEND_URL}/api/metrics/team", timeout=5.0)
        response.raise_for_status()
        return response.text
    except httpx.RequestError as e:
        return f'{{"error": "Failed to get metrics: {str(e)}"}}'
    except httpx.HTTPStatusError as e:
        return f'{{"error": "Backend error: {e.response.status_code}"}}'


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="MCP Server for AI Code Metrics")
    parser.add_argument(
        "--transport",
        type=str,
        default="stdio",
        choices=["stdio", "sse"],
        help="Transport type: stdio or sse (default: stdio)",
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8001,
        help="Port number for SSE transport (default: 8001)",
    )
    parser.add_argument(
        "--host",
        type=str,
        default="localhost",
        help="Host for SSE transport (default: localhost)",
    )

    args = parser.parse_args()

    if args.transport == "sse":
        # Run with SSE transport on specified port
        print(f"Starting MCP server on {args.host}:{args.port} with SSE transport...")
        print(f"Backend URL: {BACKEND_URL}")
        print(f"Connect Cursor to: http://{args.host}:{args.port}")

        # FastMCP with SSE transport
        # Note: FastMCP may need uvicorn for SSE, so we'll use it directly
        try:
            # Try FastMCP's built-in SSE support if available
            mcp.run(transport="sse", host=args.host, port=args.port)
        except (TypeError, ValueError) as e:
            # If FastMCP doesn't support host/port directly,
            # we need to use uvicorn with FastAPI
            print(f"Using uvicorn to run server (FastMCP limitation: {e})")
            from fastapi import FastAPI
            from fastapi.responses import StreamingResponse
            import json
            import asyncio

            app = FastAPI(title="MCP Server - AI Code Metrics")

            # Create SSE endpoint for MCP
            @app.get("/sse")
            async def sse_endpoint():
                async def event_generator():
                    # Send initial connection message
                    yield f"data: {json.dumps({'type': 'connected'})}\n\n"
                    # Keep connection alive
                    while True:
                        await asyncio.sleep(30)
                        yield f"data: {json.dumps({'type': 'ping'})}\n\n"

                return StreamingResponse(
                    event_generator(),
                    media_type="text/event-stream",
                    headers={
                        "Cache-Control": "no-cache",
                        "Connection": "keep-alive",
                    },
                )

            @app.post("/messages")
            async def handle_mcp_message(message: dict):
                # Handle MCP protocol messages
                return {"status": "ok", "message": "MCP message received"}

            uvicorn.run(app, host=args.host, port=args.port, log_level="info")
    else:
        # Run with stdio transport for Cursor/Windsurf
        mcp.run(transport="stdio")
